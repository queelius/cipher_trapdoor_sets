\documentclass[ ../main.tex]{subfiles}
\providecommand{\mainx}{..}

\SetKwFunction{MakeSingularHashSet}{make\_singular\_hash\_set}
\SetKwFunction{sampler}{random\_bit\_length}

\begin{document}
\appendix
\appendixpage
\addappheadtotoc
\section{Probability mass of random bit length}
% TODO: talk about a prefix bit string of size p such that there are
% 2^p possible sequences, thus for sufficiently large p if we
% randomly choose one and then marginalize, we have a sampling distribution
% of positive approximate oblivious sets that approaches the distribution
% of a random approximate set. As p goes to infinity, it converges in
% distribution to the random approximate set distribution. Note that even if
% p = 0, we still can treat it as an approximate set that quantifies our
% uncertainty, but for the oblivious set we do not want a given objective
% set to map to the same thing, we want it to have a distribution. The entropy
% will be given by ?
\begin{algorithm}
    \caption{Bit length sampler of \gls*{gls-shs}}
    \label{alg:sampler}
    \SetKwProg{func}{function}{$\colon$}{}
    \KwIn
    {
        $m$ is the cardinality of the random set to approximate and $\fprate$ is the \gls{gls-fprate}.
    }
    \KwOut
    {
        A \emph{minimum bit length} $n$ of a \gls{gls-shs} conditioned on a random set with cardinality $m$ and a \gls{gls-fprate} $\fprate$.
    }
    \func{\sampler{$m$,$\fprate$}}
    {
        $\Set{S} \gets \emptyset$\;
        \For{$i \gets 1$ \KwTo $m$}
        {
            $x \gets $ randomly draw a bit string from $\Set{B}^{*}$ without 
            replacement\;
            $\Set{S} \gets \Set{S} \cup \{x\}$\;
        }    
        $(h_k,b_n) \gets$ \MakeSingularHashSet{$\Set{S}$, $\fprate$}\;
        \Return $k + n + \mathcal{O}(1)$\;
    }
\end{algorithm}

For a particular $n$, each $b_n \in \Set{B}^n$ may fail to result in a perfect collision, therefore $n$ is uncertain and takes on particular values with probabilities given by the following theorem.
\begin{definition}
\label{thm:N_pmf}
The \gls{gls-shs} generator given by \cref{alg:ph} finds a random string of a random bit length given by
\begin{equation}
    \RV{N} = \sampler(m, \fprate)\,,
\end{equation}
conditioned on a random set of cardinality $m$ and a \gls{gls-fprate} $\fprate$.
\end{definition}

\begin{theorem}
The random bit length $\RV{N}$ has a probability mass function given by
\begin{equation}
\label{eq:N_pmf}
    \PDF{n \Given m, \fprate}[\RV{N}] = q^{2^n-1}\left(1 - q^{2^n}\right)\,,
\end{equation}
where $q = 1 - \fprate^{m-1}$, $m$ is the cardinality of the random set, and $\fprate$ is the \gls{gls-fprate}.
\end{theorem}
\begin{proof}
Consider that, approximately,
\begin{equation}
    \RV{N} = \log_2 \RV{Q}\,.
\end{equation}

Thus, the probability mass function is given by
\begin{align}
    \PDF{n \Given m,\fprate}[\RV{N}]
        &= \Prob{\RV{N} = n}\\
        &= \Prob{\log_2 \RV{Q} = n}\\
        &= \Prob{\RV{Q} = 2^n}\\
        &= \PDF{2^n \Given m, \fprate}[\RV{Q}]\\
        &= \fprate^{m-1} (1 - \fprate^{m-1})^{2^n}
\end{align}

%Each iteration of the loop in \cref{alg:ph} has a collision test which is Bernoulli distributed with a probability of success $\fprate^{m-1}$, where success denotes a perfect collision. We are interested in the random length $\RV{N}$ of the bit string when this outcome occurs.
%
%For the random variable $\RV{N}$ to realize a value $n$, every bit string smaller than length $n$ must fail and a bit string of length $n$ must succeed. There are $2^n-1$ bit strings smaller than length $n$ and each one fails with probability $q$, and so by the product rule the probability that they all fail is given by
%\begin{equation}
%\label{eq:N_pmf_1}
%q^{2^n - 1}\,.
%\end{equation}
%
%Given that every bit string smaller than length $n$ fails, what is the probability that every bit string of length $n$ fails? There are $2^n$ bit strings of length $n$, each of which fails with probability $q$ as before and thus by the product rule the probability that they all fail is $q^{2^n}$, whose complement, the probability that not all bit strings of length $n$ fail, is given by
%\begin{equation}
%\label{eq:N_pmf_2}
%1 - q^{2^n}\,.
%\end{equation}
%By the product rule, the probability that every bit string smaller than length $n$ fails and a bit string of length $n$ succeeds is given by the product of (\ref{eq:N_pmf_1}) and (\ref{eq:N_pmf_2}),
%\begin{equation}
%\label{eq:prob_is_mass}
%q^{2^n-1}\left(1 - q^{2^n}\right)\,.
%\end{equation}
%For \Cref{eq:prob_is_mass} to be a probability mass function, two conditions must be met. First, its image must be a subset of $[0,1]$. Second, the summation over its domain must be $1$.
%
%The first case is trivially shown by the observation that $q$ is a positive number between $0$ and $1$ and therefore any non-negative power of $q$ is positive number between $0$ and $1$.
%
%The second case is shown by calculating the infinite series
%\begin{align}
%S &= \sum_{n=0}^{\infty} q^{2^n-1}\left(1-q^{2^n}\right)\\
%&= \sum_{n=0}^{\infty} q^{2^n-1} - q^{2^{n+1}-1}\,.
%\end{align}
%Explicitly evaluating this series for the first $4$ terms reveals a telescoping sum given by
%\begin{equation}
%S = (1 - q) + (q - q^3) + (q^3 - q^7) + (q^7 - q^{15}) + \cdots\,,
%\end{equation}
%where everything cancels except $1$.
%


\end{proof}


% \section{Exact singular hash set}

% \begin{algorithm}
%     \caption{Implementation of \protect\MakeSingularHashSet over a universal 
%     set $\Set{U}$}
%     \label{alg:makeexactobset}
%     \DontPrintSemicolon
%     \SetKwProg{func}{function}{}{}
%     \KwIn
%     {
%         $\Set{S}$ is a subset of a finite universal set $\Set{U}$.
%         $k$ is any number in the set $\{1,2,\ldots\}$.
%     }
%     \KwOut
%     {
%         An \emph{oblivious} exact set of $\Set{S}$.
%     }
%     \func{\MakeSingularHashSet{$\Set{S}, k$}}
%     {
%         $\Set{S}_{\BitSet} \gets \left\{\Encode_{\Set{U} \mapsto \BitSet}(x) \colon x \in \Set{S}\right\}$\;
%         $\Set{\overline{S}}_{\BitSet} \gets \left\{\Encode_{\Set{U} \mapsto \BitSet}(x) \colon x \in \Set{\overline{S}}\right\}$\;        
%         \tcp{To find the smallest bit string, search for a bit string of length $n$ in ascending order.}
%         \For{$n \gets 0$ \KwTo $\infty$}
%         {
%             \For{$j \gets 1$ \KwTo $2^n$}
%             {
%                 $\found \gets 1$\;
%                 \tcp{To maximize \emph{entropy} we try bit strings of length 
%                 $n$ in random order.}
%                 $b_n \gets $ a bit string of length $n$ randomly drawn from $\BitSet[n]$ without replacement\;
%                 $h_k \gets \Null$\;
%                 \For{$x \in \Set{S}_{\BitSet}$}
%                 {
%                     \If{$h_k = \Null$}
%                     {
%                         $h_k \gets \hash\!\left(x \cat b_n\right) \mod (k+1)$\;
%                     }
%                     \ElseIf{$h_k \neq \hash\!\left(x \cat b_n\right) \mod 
%                     (k+1)$} 
%                     {
%                         $\found \gets \False$\;
%                     }
%                 }
%                 \For{$x \in \Set{\overline{S}}_{\BitSet}$}
%                 {
%                     \If{$h_k = \hash\!\left(x \cat b_n\right) \mod (k+1)$} 
%                     {
%                         $\found \gets \False$\;
%                     }
%                 }
%                 \If{\found}
%                 {
%                     \Return $(h_k, b_n)$\;
%                 }
%             }
%         }
%     }
% \end{algorithm}


% Exact oblivious set:
% \begin{equation}
%     k (\rho u - 1) + (u \log_2(1 - 2^{-k})(\rho - 1)
% \end{equation}

% \begin{equation}
%     k (\rho u - 1)/m + (u \log_2(1 - 2^{-k})(\rho - 1)/m
% \end{equation}

% \begin{equation}
%     k\left(1 - \frac{1}{u \rho}\right) + \log_2\!\left(1 - 2^{-k}\right)\left(1 - \frac{1}{\rho}\right)
% \end{equation}

% \begin{equation}
%     k (\rho - \frac{1}{u}) + \log_2(1 - 2^{-k}(\rho - 1) \; \si{bits \per element in universal set}
% \end{equation}


% \begin{theorem}
% \begin{equation}
%     \min_k k (\rho - \frac{1}{u}) + \log_2\!\left(1 - 2^{-k}(\rho - 1)\right)
% \end{equation}
% bits per element in the universal set $\Set{U}$ where $u = \Card{\Set{U}}$. 
% \end{theorem}





% The above algortihm for generating exact oblivious sets has a space complexity of $u$ bits. Assuming $m$ is not too much smaller than $u$, i.e., $\Set{S}$ is dense, this is the theoretical lower-bound for sets over finite universes.

% If $m$ is not dense, then trying larger singular hash lengths will result in a better lower-bound.

% Suppose you are interested in creating exact oblivious sets over the universe of bit strings up to length $n$, denoted by $\BitSet[\leq n]$. Then, there are $\Card{\BitSet[\leq n]} = 2^{n+1} - 1$ bit strings in the universe. In this case, the set has a lower-bound given by
% $\mathcal{O}(n)$.



























% We may trade space complexity for entropy if desired. For instance, if the policy is to search for a bit string of a length $t$ much larger than the expected bit length, $-m \log_2 \fprate$, then
% \begin{equation}
%     m < -\frac{t}{\log_2 \fprate}\,.
% \end{equation}
% Thus, an estimator of the upper-bound on the cardinality is given by
% \begin{equation}
%     \hat{m}_{\rm{max}} \approx -\frac{t}{\log_2 \fprate}
% \end{equation}
% and an estimate of the \emph{lower-bound} is $0$ (the empty set) where the cardinality is uniformly distributed (maximum entropy) between $0$ and $\hat{m}_{\rm{max}}$, which has an entropy given by
% \begin{equation}
%     \log_2(1+\hat{m}_{\rm{max}})\,.
% \end{equation}

% The absolute space efficiency is now given by
% \begin{equation}
%     \frac{m}{\hat{m}_{\rm{max}}}\,,
% \end{equation}
% which is the \emph{maximum} efficiency possible for an approximate set with a cardinality uniformly distributed between $0$ and $\hat{m}_{\RV{max}}$.

% \begin{example}
% Suppose $t = r m, r > 1$, then
% \begin{equation}
%     \hat{m}_{\rm{max}} \approx -\frac{r m}{\log_2 \fprate}
% \end{equation}
% which has an entropy given by
% \begin{equation}
%     \log_2\!\left(1 -\frac{r m}{\log_2 \fprate}\right) \approx \log_2 r + \log_2 m + \log_2 \frac{1}{\fprate}
% \end{equation}
% and an absolute space efficiency $r$.
% \end{example}










\end{document}